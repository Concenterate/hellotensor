{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First impression with Chainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import numpy as np\n",
    "\n",
    "from chainer import *\n",
    "\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the chainer essentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43237969,  3.89886069],\n",
       "       [-1.35355818,  8.12027836]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = L.Linear(3,2) # dense MLP\n",
    "\n",
    "x = Variable(np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)) # input\n",
    "y = f(x) # process\n",
    "y.data # output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per documentation:\n",
    "\n",
    ">Gradients of parameters are computed by the backward() method. Note that gradients are accumulated by the method rather than overwritten. So first you must clear gradients to renew the computation. It can be done by calling the cleargrads() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  7.  9.]\n",
      " [ 5.  7.  9.]]\n",
      "[ 2.  2.]\n"
     ]
    }
   ],
   "source": [
    "f.cleargrads() # clear gradients of f\n",
    "\n",
    "y.grad = np.ones((2, 2), dtype=np.float32) # provide ones as initial gradient\n",
    "y.backward() # do backprop\n",
    "\n",
    "# now the parameters have gradient\n",
    "print(f.W.grad)\n",
    "print(f.b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43237969,  3.89886069],\n",
       "       [-1.35355818,  8.12027836]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.W.data -= f.W.grad\n",
    "f.b.data -= f.b.grad\n",
    "\n",
    "y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
